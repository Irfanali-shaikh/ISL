{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4a84945",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import mediapipe as mp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from preprocess import mediapipe_detection,landmarks,draw_styled_landmarks,extract_keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5641150",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM,Dense,GRU,Dropout\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow import keras\n",
    "from sklearn.metrics import multilabel_confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fcf30589",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH_train = os.path.join('Alpha_train')\n",
    "DATA_PATH_test = os.path.join('Alpha_test')\n",
    "#no_sequences = 50 #number of videos\n",
    "sequence_length = 1000     #number of frames per video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "39821f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax_train = os.listdir(r'E:\\M.Tech\\Dissertation Stage 2 - Final\\Final Character\\Alpha_train')\n",
    "actions_train = []\n",
    "label_map_train = {}\n",
    "ax_test = os.listdir(r'E:\\M.Tech\\Dissertation Stage 2 - Final\\Final Character\\Alpha_test')\n",
    "actions_test = []\n",
    "label_map_test = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "488866b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range(len(ax_train)):\n",
    "    label_map_train[ax[a]]=a\n",
    "    actions_train.append(ax[a])\n",
    "for a in range(len(ax_test)):\n",
    "    label_map_test[ax[a]]=a\n",
    "    actions_test.append(ax[a])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "87492f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'J': 9, 'K': 10, 'L': 11, 'M': 12, 'N': 13, 'O': 14, 'P': 15, 'Q': 16, 'R': 17, 'S': 18, 'Space': 19, 'T': 20, 'U': 21, 'V': 22, 'W': 23, 'X': 24, 'Y': 25, 'Z': 26}\n",
      "['A' 'B' 'C' 'D' 'E' 'F' 'G' 'H' 'I' 'J' 'K' 'L' 'M' 'N' 'O' 'P' 'Q' 'R'\n",
      " 'S' 'Space' 'T' 'U' 'V' 'W' 'X' 'Y' 'Z']\n"
     ]
    }
   ],
   "source": [
    "action = np.array(actions)\n",
    "action.shape\n",
    "print(label_map)\n",
    "print(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e1bc6930",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_train, labels_train = [],[]\n",
    "for axs in actions_train:\n",
    "    window_train = []\n",
    "    for frame_num in range(0,800):\n",
    "        res = np.load(os.path.join(DATA_PATH_train, axs,\"{}.npy\".format(frame_num)))\n",
    "        window_train.append(res)\n",
    "        #print(np.array(window).shape)\n",
    "    sequences_train.append(window_train)\n",
    "\n",
    "    labels_train.append(label_map_train[axs])\n",
    "    \n",
    "\n",
    "sequences_test, labels_test = [],[]\n",
    "for axs in actions_test:\n",
    "    window_test = []\n",
    "    for frame_num in range(800,1000):\n",
    "        res = np.load(os.path.join(DATA_PATH_test, axs,\"{}.npy\".format(frame_num)))\n",
    "        window_test.append(res)\n",
    "        #print(np.array(window).shape)\n",
    "    sequences_test.append(window_test)\n",
    "\n",
    "    labels_test.append(label_map_test[axs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "19f21417",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 800, 126)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(sequences_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c21373c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21600,)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(labels_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "acd8013a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train  = np.array(sequences_train)\n",
    "y_train = to_categorical(labels_train).astype(int)\n",
    "x_test  = np.array(sequences_test)\n",
    "y_test = to_categorical(labels_test).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e536fe0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21600, 27)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a35836dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 800, 126)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5dbf0f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nmodel = Sequential()\\nmodel.add(GRU(256,return_sequences = True, activation = 'tanh',input_shape = (30,1662)))\\nmodel.add(Dropout(0.3))\\nmodel.add(GRU(512,return_sequences = True, activation = 'tanh'))\\nmodel.add(Dropout(0.3))\\nmodel.add(GRU(256,return_sequences = False, activation = 'tanh'))\\nmodel.add(Dropout(0.3))\\nmodel.add(Dense(256, activation = 'tanh'))\\nmodel.add(Dropout(0.3))\\nmodel.add(Dense(128, activation = 'tanh'))\\nmodel.add(Dense(action.shape[0],activation = 'softmax'))\\n\""
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(256, activation = 'relu',input_shape = (800,126)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(128, activation = 'relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(action.shape[0],activation = 'softmax'))\n",
    "'''\n",
    "model = Sequential()\n",
    "model.add(GRU(256,return_sequences = True, activation = 'tanh',input_shape = (30,1662)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(GRU(512,return_sequences = True, activation = 'tanh'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(GRU(256,return_sequences = False, activation = 'tanh'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(256, activation = 'tanh'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(128, activation = 'tanh'))\n",
    "model.add(Dense(action.shape[0],activation = 'softmax'))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "3d7b7381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_10 (Dense)             (None, 800, 256)          32512     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 800, 256)          0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 800, 128)          32896     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 800, 128)          0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 800, 64)           8256      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 800, 64)           0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 800, 64)           4160      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 800, 27)           1755      \n",
      "=================================================================\n",
      "Total params: 79,579\n",
      "Trainable params: 79,579\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam',loss='categorical_crossentropy',metrics = ['categorical_accuracy'])\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f6c6f774",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 27\n  y sizes: 21600\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-95-d00f5eeb04cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#scores = model.evaluate(x_train, y_train)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1131\u001b[0m          \u001b[0mtraining_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRespectCompiledTrainableState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m       \u001b[1;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1133\u001b[1;33m       data_handler = data_adapter.get_data_handler(\n\u001b[0m\u001b[0;32m   1134\u001b[0m           \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1135\u001b[0m           \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1362\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"model\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_cluster_coordinator\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1363\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1364\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[0;32m   1152\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_verify_data_adapter_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madapter_cls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1154\u001b[1;33m     self._adapter = adapter_cls(\n\u001b[0m\u001b[0;32m   1155\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[0mnum_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m     \u001b[0m_check_data_cardinality\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[1;31m# If batch_size is not passed but steps is, calculate from the input data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m_check_data_cardinality\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1628\u001b[0m           label, \", \".join(str(i.shape[0]) for i in nest.flatten(single_data)))\n\u001b[0;32m   1629\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m\"Make sure all arrays contain the same number of samples.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1630\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1631\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1632\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 27\n  y sizes: 21600\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs = 10, batch_size = 5)\n",
    "#scores = model.evaluate(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b06c5d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc55bec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
