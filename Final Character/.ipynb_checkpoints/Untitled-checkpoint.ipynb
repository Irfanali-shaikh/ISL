{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "451d8094",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ca22e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"ISL_train.csv\")\n",
    "test_df = pd.read_csv(\"ISL_test.csv\")\n",
    "\n",
    "y_train = train_df['Label']\n",
    "y_test = test_df['Label']\n",
    "del train_df['Label']\n",
    "del test_df['Label']\n",
    "#print(x_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85e5d54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_train = label_binarizer.fit_transform(y_train)\n",
    "y_test = label_binarizer.fit_transform(y_test)\n",
    "x_train = train_df.values\n",
    "x_test = test_df.values\n",
    "\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "x_train = x_train.reshape(-1,28,28,1)\n",
    "x_test = x_test.reshape(-1,28,28,1)\n",
    "nsamples, nx, ny = x_train.shape\n",
    "print(nsamples, nx, ny )\n",
    "#d2_train_dataset = train_dataset.reshape((nsamples,nx*ny))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "965f3180",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 4. Estimator expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-b6ffe511f364>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    302\u001b[0m                 \u001b[1;34m\"sparse multilabel-indicator for y is not supported.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m             )\n\u001b[1;32m--> 304\u001b[1;33m         X, y = self._validate_data(X, y, multi_output=True,\n\u001b[0m\u001b[0;32m    305\u001b[0m                                    accept_sparse=\"csc\", dtype=DTYPE)\n\u001b[0;32m    306\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 433\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    434\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    812\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y cannot be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 814\u001b[1;33m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[0;32m    815\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    816\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    657\u001b[0m                     \"into decimal numbers with dtype='numeric'\") from e\n\u001b[0;32m    658\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 659\u001b[1;33m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n\u001b[0m\u001b[0;32m    660\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[0;32m    661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with dim 4. Estimator expected <= 2."
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model=RandomForestClassifier()\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab373c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_preprocess(path):\n",
    "    im = Image.open(path,'r')\n",
    "    im = ImageOps.grayscale(im)\n",
    "    im = im.resize((28,28), Image.ANTIALIAS)\n",
    "    pix = np.array(im.getdata()).flatten()\n",
    "    return pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4f5574",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = \"E:\\M.Tech\\Dissertation Stage 2 - Final\\Final Word\\Untitled Folder\\Indian\\D\\o.jpg\"\n",
    "test = image_preprocess(img)\n",
    "test.shape\n",
    "'''\n",
    "y_train = label_binarizer.fit_transform(y_train)\n",
    "y_test = label_binarizer.fit_transform(y_test)\n",
    "print(x_train.shape,y_train.shape)\n",
    "x_train = train_df.values\n",
    "x_test = test_df.values\n",
    "\n",
    "x_train = x_train / 255\n",
    "x_test = x_test / 255\n",
    "\n",
    "x_train = x_train.reshape(-1,28,28,1)\n",
    "x_test = x_test.reshape(-1,28,28,1)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da74b925",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=model.predict(test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2a4a35",
   "metadata": {},
   "source": [
    "The code above starts by reshaping all of the training image files so the model understands the input files. Along with this, the LabelBinarizer() variable takes the classes in the dataset and converts them to binary, a process that greatly speeds up the training of the model.\n",
    "\n",
    "The next step is to create the data generator to randomly implement changes to the data, increasing the amount of training examples and making the images more realistic by adding noise and transformations to different instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "71501c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,\n",
    "        samplewise_center=False, \n",
    "        featurewise_std_normalization=False,\n",
    "        samplewise_std_normalization=False,\n",
    "        zca_whitening=False,\n",
    "        rotation_range=10,\n",
    "        zoom_range = 0.1, \n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        horizontal_flip=False,\n",
    "        vertical_flip=False)\n",
    "\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d08db84",
   "metadata": {},
   "source": [
    "After processing the images, the CNN model must be compiled to recognize all of the classes of information being used in the data, namely the 24 different groups of images. Normalization of the data must also be added to the data, equally balancing the classes with less images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0dec69f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(75 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu' , input_shape = (28,28,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Conv2D(50 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Conv2D(25 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units = 512 , activation = 'relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units = 27 , activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197aebaa",
   "metadata": {},
   "source": [
    "Notice the initialization of the algorithm with the adding of variables such as the Conv2D model, and the condensing to 24 features. We also use batching techniques to allow the CNN to handle the data more efficiently.\n",
    "\n",
    "Finally, defining the loss functions and metrics along with fitting the model to the data will create our Sign Language Recognition system. It is important to recognize the model.save() command at the end of the statement due to the length of time required to build the model. Re-training the model for every use can take hours of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "e845427e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 28, 28, 75)        750       \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 28, 28, 75)        300       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 14, 14, 75)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 14, 14, 50)        33800     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 14, 14, 50)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 14, 14, 50)        200       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 7, 7, 50)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 7, 7, 25)          11275     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 7, 7, 25)          100       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 4, 4, 25)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               205312    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 27)                13851     \n",
      "=================================================================\n",
      "Total params: 265,588\n",
      "Trainable params: 265,288\n",
      "Non-trainable params: 300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer = 'adam' , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3eac79a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21708, 28, 28, 1) (21708, 27)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape,y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "69aee56d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "170/170 [==============================] - 47s 274ms/step - loss: 8.8326e-04 - accuracy: 0.9997 - val_loss: 1.8067e-05 - val_accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "170/170 [==============================] - 47s 279ms/step - loss: 4.0794e-04 - accuracy: 0.9999 - val_loss: 1.5675e-05 - val_accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "170/170 [==============================] - 49s 288ms/step - loss: 3.9518e-04 - accuracy: 0.9999 - val_loss: 8.3125e-05 - val_accuracy: 0.9999\n",
      "Epoch 4/20\n",
      "170/170 [==============================] - 49s 289ms/step - loss: 1.1082e-04 - accuracy: 1.0000 - val_loss: 1.0632e-05 - val_accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "170/170 [==============================] - 49s 288ms/step - loss: 2.7229e-04 - accuracy: 0.9999 - val_loss: 3.9945e-05 - val_accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "170/170 [==============================] - 50s 291ms/step - loss: 4.3124e-04 - accuracy: 0.9999 - val_loss: 7.3797e-06 - val_accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "170/170 [==============================] - 51s 299ms/step - loss: 1.0210e-04 - accuracy: 1.0000 - val_loss: 2.1500e-05 - val_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "170/170 [==============================] - 49s 290ms/step - loss: 1.2778e-04 - accuracy: 1.0000 - val_loss: 6.0718e-06 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "170/170 [==============================] - 51s 300ms/step - loss: 5.5276e-05 - accuracy: 1.0000 - val_loss: 5.9411e-06 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "170/170 [==============================] - 51s 301ms/step - loss: 1.7525e-04 - accuracy: 1.0000 - val_loss: 1.0482e-04 - val_accuracy: 0.9999\n",
      "Epoch 11/20\n",
      "170/170 [==============================] - 49s 291ms/step - loss: 3.2160e-04 - accuracy: 0.9999 - val_loss: 2.1719e-05 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "170/170 [==============================] - 49s 291ms/step - loss: 3.0564e-04 - accuracy: 0.9999 - val_loss: 2.3084e-06 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "170/170 [==============================] - 50s 291ms/step - loss: 7.1333e-05 - accuracy: 1.0000 - val_loss: 1.1480e-05 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "170/170 [==============================] - 50s 292ms/step - loss: 2.7332e-04 - accuracy: 0.9999 - val_loss: 1.3763e-05 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "170/170 [==============================] - 49s 291ms/step - loss: 1.4792e-04 - accuracy: 1.0000 - val_loss: 3.9273e-06 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "170/170 [==============================] - 51s 298ms/step - loss: 0.0023 - accuracy: 0.9993 - val_loss: 6.5446e-05 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "170/170 [==============================] - 56s 328ms/step - loss: 7.6934e-04 - accuracy: 0.9996 - val_loss: 5.4937e-07 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "170/170 [==============================] - 50s 296ms/step - loss: 5.6282e-05 - accuracy: 1.0000 - val_loss: 4.4752e-08 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "170/170 [==============================] - 62s 362ms/step - loss: 7.6723e-05 - accuracy: 1.0000 - val_loss: 3.2758e-06 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "170/170 [==============================] - 56s 331ms/step - loss: 0.0015 - accuracy: 0.9994 - val_loss: 2.5208e-05 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(datagen.flow(x_train,y_train,batch_size = 128) ,epochs = 20 , validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5468f17f",
   "metadata": {},
   "source": [
    "This code has a lot to unpack. Let’s look at it in sections.\n",
    "\n",
    "Line 1:\n",
    "\n",
    "The model.compile() function takes many parameters, of which three are displayed in the code. The optimizer and loss parameters work together along with the epoch statement in the next line to efficiently reduce the amount of error in the model by incrementally changing computation methods on the data.\n",
    "\n",
    "Along with this, the metric of choice to be optimized is the accuracy functions, which ensures that the model will have the maximum accuracy achievable after the set number of epochs.\n",
    "\n",
    "Line 4:\n",
    "\n",
    "The function run here fits the designed model to the data from the image data developed in the first bit of code. It also defines the number of epochs or iterations the model has to enhance the accuracy of the image detection. The validation set is also called here, to introduce a testing aspect to the model. The model calculates the accuracy using this data.\n",
    "\n",
    "Line 5:\n",
    "\n",
    "Of all of the statements in the code bit, the model.save() function may be the most important part of this code, as it can potentially save hours of time when implementing the model.\n",
    "\n",
    "The model developed accurately detects and classifies Sign Language symbols with about 95% training accuracy.\n",
    "\n",
    "Now, using two popular live video processing libraries known as Mediapipe and Open-CV, we can take webcam input and run our previously developed model on real time video stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5633579",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f9a5d909",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "1adfa111",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-149-803193ff999b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mframergb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhands\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframergb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mhand_landmarks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmulti_hand_landmarks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhand_landmarks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\mediapipe\\python\\solutions\\hands.py\u001b[0m in \u001b[0;36mprocess\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m    162\u001b[0m     \"\"\"\n\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'image'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\Anaconda3\\lib\\site-packages\\mediapipe\\python\\solution_base.py\u001b[0m in \u001b[0;36mprocess\u001b[1;34m(self, input_data)\u001b[0m\n\u001b[0;32m    331\u001b[0m                                      data).at(self._simulated_timestamp))\n\u001b[0;32m    332\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 333\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait_until_idle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    334\u001b[0m     \u001b[1;31m# Create a NamedTuple object where the field names are mapping to the graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m     \u001b[1;31m# output stream names.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    _, frame = cap.read()\n",
    "\n",
    "    k = cv2.waitKey(1)\n",
    "    if k%256 == 27:\n",
    "        # ESC pressed\n",
    "        print(\"Escape hit, closing...\")\n",
    "        break\n",
    "\n",
    "    framergb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    result = hands.process(framergb)\n",
    "    hand_landmarks = result.multi_hand_landmarks\n",
    "    if hand_landmarks:\n",
    "        for handLMs in hand_landmarks:\n",
    "            x_max = 0\n",
    "            y_max = 0\n",
    "            x_min = w\n",
    "            y_min = h\n",
    "            for lm in handLMs.landmark:\n",
    "                x, y = int(lm.x * w), int(lm.y * h)\n",
    "                if x > x_max:\n",
    "                    x_max = x\n",
    "                if x < x_min:\n",
    "                    x_min = x\n",
    "                if y > y_max:\n",
    "                    y_max = y\n",
    "                if y < y_min:\n",
    "                    y_min = y\n",
    "            y_min -= 20\n",
    "            y_max += 20\n",
    "            x_min -= 20\n",
    "            x_max += 20\n",
    "            cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "            mp_drawing.draw_landmarks(frame, handLMs, mphands.HAND_CONNECTIONS)\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5555aed1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-d7d2bd5cecf3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m     \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m%\u001b[0m\u001b[1;36m256\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m27\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[1;31m# ESC pressed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = load_model('character.h5')\n",
    "\n",
    "mphands = mp.solutions.hands\n",
    "hands = mphands.Hands()\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "_, frame = cap.read()\n",
    "h, w, c = frame.shape\n",
    "\n",
    "analysisframe = ''\n",
    "letterpred = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I','J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y','Z','Space']\n",
    "\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    \n",
    "    k = cv2.waitKey(1)\n",
    "    if k%256 == 27:\n",
    "        # ESC pressed\n",
    "        print(\"Escape hit, closing...\")\n",
    "        break\n",
    "    elif k%256 == 32:\n",
    "        # SPACE pressed\n",
    "        # SPACE pressed\n",
    "        analysisframe = frame\n",
    "        showframe = analysisframe\n",
    "        cv2.imshow(\"Frame\", showframe)\n",
    "        framergbanalysis = cv2.cvtColor(analysisframe, cv2.COLOR_BGR2RGB)\n",
    "        resultanalysis = hands.process(framergbanalysis)\n",
    "        hand_landmarksanalysis = resultanalysis.multi_hand_landmarks\n",
    "        if hand_landmarksanalysis:\n",
    "            for handLMsanalysis in hand_landmarksanalysis:\n",
    "                x_max = 0\n",
    "                y_max = 0\n",
    "                x_min = w\n",
    "                y_min = h\n",
    "                for lmanalysis in handLMsanalysis.landmark:\n",
    "                    x, y = int(lmanalysis.x * w), int(lmanalysis.y * h)\n",
    "                    if x > x_max:\n",
    "                        x_max = x\n",
    "                    if x < x_min:\n",
    "                        x_min = x\n",
    "                    if y > y_max:\n",
    "                        y_max = y\n",
    "                    if y < y_min:\n",
    "                        y_min = y\n",
    "                y_min -= 20\n",
    "                y_max += 20\n",
    "                x_min -= 20\n",
    "                x_max += 20 \n",
    "\n",
    "        analysisframe = cv2.cvtColor(analysisframe, cv2.COLOR_BGR2GRAY)\n",
    "        analysisframe = analysisframe[y_min:y_max, x_min:x_max]\n",
    "        analysisframe = cv2.resize(analysisframe,(28,28))\n",
    "\n",
    "\n",
    "        nlist = []\n",
    "        rows,cols = analysisframe.shape\n",
    "        for i in range(rows):\n",
    "            for j in range(cols):\n",
    "                k = analysisframe[i,j]\n",
    "                nlist.append(k)\n",
    "        \n",
    "        datan = pd.DataFrame(nlist).T\n",
    "        colname = []\n",
    "        for val in range(784):\n",
    "            colname.append(val)\n",
    "        datan.columns = colname\n",
    "\n",
    "        pixeldata = datan.values\n",
    "        pixeldata = pixeldata / 255\n",
    "        pixeldata = pixeldata.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36b7980c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pixeldata' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-b2ccba217b3c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpixeldata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpredarray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mletter_prediction_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mletterpred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpredarray\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mletterpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpredarrayordered\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mhigh1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredarrayordered\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pixeldata' is not defined"
     ]
    }
   ],
   "source": [
    "prediction = model.predict(pixeldata)\n",
    "predarray = np.array(prediction[0])\n",
    "letter_prediction_dict = {letterpred[i]: predarray[i] for i in range(len(letterpred))}\n",
    "predarrayordered = sorted(predarray, reverse=True)\n",
    "high1 = predarrayordered[0]\n",
    "high2 = predarrayordered[1]\n",
    "high3 = predarrayordered[2]\n",
    "for key,value in letter_prediction_dict.items():\n",
    "    if value==high1:\n",
    "        print(\"Predicted Character 1: \", key)\n",
    "        print('Confidence 1: ', 100*value)\n",
    "    elif value==high2:\n",
    "        print(\"Predicted Character 2: \", key)\n",
    "        print('Confidence 2: ', 100*value)\n",
    "    elif value==high3:\n",
    "        print(\"Predicted Character 3: \", key)\n",
    "        print('Confidence 3: ', 100*value)\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84bd4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64edd704",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47835539",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84557cf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9b23db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e526838",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "3d3b0da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('character.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1698208f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32400, 28, 28, 1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "19507b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10692, 27)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8064dd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
